---
title: "Model summaries for a Bayesian linear regression"
author: "Sam Clifford"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
<<<<<<< Updated upstream

The packages `dsmcmc` creates tidy summaries of Bayesian models, in the fashion of `broom`, with one important difference - `dsmcmc` uses a `data.table` instead of a `tibble`, due to the size of the output that is all too easily possible in Bayesian models.
=======
<<<<<<< Updated upstream
>>>>>>> Stashed changes
  
  
```{r, echo = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "README-",
message=FALSE, warning=FALSE
)
<<<<<<< Updated upstream
=======

library(dsmcmc)
=======

The packages `mmcc` creates tidy summaries of Bayesian models, in the fashion of `broom`, with one important difference - `mmcc` uses a `data.table` instead of a `tibble`, due to the size of the output that is all too easily possible in Bayesian models.
  
The aim of this vignette is to demonstrate how to use the two key functions of `mmcc`, `mcmc_to_dt()` and `tidy` (which actually calls `mmcc:::tidy.mcmc.list` under the hood).

```{r setup, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE,
                      message=FALSE, 
                      warning=FALSE)
>>>>>>> Stashed changes
>>>>>>> Stashed changes
```

First, we simulate some data

``` {r, fig.align="center"}
set.seed(4000)
N <- 20
x <- sort(runif(n = N))
y <- rnorm(n=N, mean = 2*x + 1, sd=0.25)
dat <- data.frame(x = x, y = y)

library(ggplot2)
ggplot(data=dat,
       aes(x=x, y=y)) +
    geom_point() +
    theme_bw()
```

and some values for predicting
``` {r}
M <- 10
x.pred <- seq(from=min(x), to=max(x), length.out = M)
```

We will fit the model, specified as,

```{r comment='', echo=F}
cat(readLines('model.txt'), sep = '\n')
```

and therefore generate the `mcmc_object` with the `rjags` package.

``` {r}
library(rjags)
model <- jags.model(file = "model.txt",
                    data = list(n = N,
                                x = x,
                                y = y,
                                m = M,
                                x.pred = x.pred))
```

Draw burn-in samples and posterior inference samples for all terms in the model.

``` {r}
burn <- jags.samples(model,
                     c("beta.0", "beta.1", "tau.y", "mu"),
                     n.iter = 5000)

samples <- coda.samples(model,
                        c("beta.0", "beta.1", "tau.y", "mu.pred", "y.pred"),
                        n.iter = 10000)

```

We can now convert the posterior samples to a data table and summarise the regression parameters

<<<<<<< Updated upstream
``` {r rjags-summarise}
library(dsmcmc)
<<<<<<< Updated upstream
=======
library(broom)
=======
<<<<<<< Updated upstream
``` {r}
library(dsmcmc)
=======
``` {r rjags-summarise}
library(mmcc)
# library(broom)
>>>>>>> Stashed changes
>>>>>>> Stashed changes
>>>>>>> Stashed changes

samples_dt <- mcmc_to_dt(samples)
samples_dt

pars_dt <- tidy.mcmc.list(samples, conf.level=0.95, 
                          colnames = c("beta.0", "beta.1", "tau.y"))
pars_dt
```

Summarise the line of best fit, `mu`, and the predictions, `y.pred`,

``` {r}
mu_dt <- tidy.mcmc.list(samples, conf.level=0.95, colnames =  "mu.pred")
y_dt <- tidy.mcmc.list(samples, conf.level=0.95, colnames =  "y.pred")
```

For plotting, we add the prediction $\boldsymbol{x}$ values to these data tables for plotting

``` {r}
mu_dt[, x:= x.pred ]
y_dt[ , x:= x.pred ]

y_dt
```

Now we'll generate a plot that shows the data, a 95% credible interval for the predictions, ${\hat{\boldsymbol{y}}}_{pred}$, and a 95% credible interval for their means, ${\hat{\boldsymbol{\mu}}}_{pred}$.

<<<<<<< Updated upstream
``` {r dsmcmc-plot-cr-i, fig.align="center", echo=F}
=======
<<<<<<< Updated upstream
``` {r, fig.align="center", echo=F}
ggplot(data=dat,
       aes(x=x)) +
    geom_point(aes(y=y)) +
    geom_ribbon(aes(ymin = `2.5%`,
=======
``` {r mmcc-plot-cr-i, fig.align="center", echo=F}
>>>>>>> Stashed changes
ggplot(data = dat,
       aes(x = x)) +
    geom_point(aes(y = y)) +
    geom_ribbon(data = mu_dt,
                aes(ymin = `2.5%`,
<<<<<<< Updated upstream
=======
>>>>>>> Stashed changes
>>>>>>> Stashed changes
                    ymax = `97.5%`),
                fill = "salmon",
                alpha = 0.5,
                data = mu_dt) +
    geom_ribbon(aes(ymin = `2.5%`,
                    ymax = `97.5%`),
                fill = "lightskyblue",
                alpha = 0.25,
                data = y_dt) +
    geom_line(aes(y = Mean),
              data=y_dt) +
    theme_bw()
```

If we tidy the `samples` object, we can look at the distribution of values

<<<<<<< Updated upstream
``` {r dsmcmc-value-distr, fig.height=2, fig.width=7}
=======
<<<<<<< Updated upstream
``` {r, fig.height=2, fig.width=7}
=======
``` {r mmcc-value-distr, fig.height=2, fig.width=7}
>>>>>>> Stashed changes
>>>>>>> Stashed changes
tidy_samples <- mcmc_to_dt(samples, 
                           colnames = c("beta.0", "beta.1", "tau.y"))

ggplot(data=tidy_samples, aes(x=value)) +
    geom_density(color="black", fill="grey90") +
    facet_wrap( ~ parameter,
                nrow = 1,
                scales="free") +
    theme_bw() +
    geom_segment(data=pars_dt,
                   aes(x = `2.5%`,
                       xend = `97.5%`),
                 y = 0, yend = 0,
                 size=2) +
    geom_point(data=pars_dt,
               aes(x=Mean),
               y = 0,
               color="white")
```
